{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from numpy.testing import assert_array_almost_equal, assert_equal, assert_almost_equal\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Первое обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простое как пробка задание. Обучите классификатор [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) на входных данных с гиперпараметрами:\n",
    "\n",
    "* `max_depth`=$6$\n",
    "* `min_samples_split`=$3$\n",
    "* `min_samples_leaf`=$3$\n",
    "* `n_estimators`=$100$\n",
    "* `n_jobs`=$-1$\n",
    "\n",
    "И верните обученную модель.\n",
    "\n",
    "Данные в X только численные, в y только 2 значения: 0 и 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def fit_rf(X: np.ndarray, y:np.ndarray) ->  RandomForestClassifier:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'n_estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m y_clf \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([np\u001b[38;5;241m.\u001b[39mzeros(n), np\u001b[38;5;241m.\u001b[39mones(n)]) \u001b[38;5;66;03m# бинарный признак\u001b[39;00m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m fit_rf(X_clf, y_clf)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m model\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m model\u001b[38;5;241m.\u001b[39mmin_samples_split \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'n_estimators'"
     ]
    }
   ],
   "source": [
    "######################################################\n",
    "np.random.seed(1337)\n",
    "n = 200\n",
    "a = np.random.normal(loc=0, scale=1, size=(n, 2)) # первый класс\n",
    "b = np.random.normal(loc=3, scale=2, size=(n, 2)) # второй класс\n",
    "X_clf = np.vstack([a, b]) # двумерный количественный признак\n",
    "y_clf = np.hstack([np.zeros(n), np.ones(n)]) # бинарный признак\n",
    "\n",
    "model = fit_rf(X_clf, y_clf)\n",
    "assert model.n_estimators == 100\n",
    "assert model.max_depth == 6\n",
    "assert model.min_samples_split == 3\n",
    "assert model.min_samples_leaf == 3\n",
    "\n",
    "assert_equal(model.predict(np.array([[0, 0]])), np.array([0.]))\n",
    "assert_equal(model.predict(np.array([[3, 3]])), np.array([1.]))\n",
    "######################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Первая классификация"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В [папке data](data/) вы можете найти данные для бинарной классификации (`diabets_train.csv`, `diabets_test.csv` и `diabetes_answers.csv`). $Y$ в этих данных выступает столбик `Outcome`, в качестве $X$ - все остальное. \n",
    "\n",
    "Вам необходимо предсказать $y_{test}$ такой, что $accuracy > 0.75$ ([доля правильных ответов](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)). Вы можете делать что угодно, чтобы получить результат:\n",
    "\n",
    "* использовать любой классификатор с любыми гиперпараметрами\n",
    "* как угодно изменять данные \n",
    "\n",
    "Вернуть в этом случае нужно не модель, а результат - одномерный массив данных $y_{pred}$ (предсказание $y_{test}$).\n",
    "\n",
    "P.S. Можете узнать больше о данных по [ссылке](https://www.kaggle.com/uciml/pima-indians-diabetes-database). Мы произвольным образом разбили данные в соотношении 4:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def classification(X_train: np.ndarray, y_train: np.ndarray, X_test: np.ndarray) -> np.ndarray:\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "df_train = pd.read_csv('data/diabetes_train.csv')\n",
    "df_test = pd.read_csv('data/diabetes_test.csv')\n",
    "\n",
    "X_train = df_train.drop(columns=['Outcome']).values\n",
    "y_train = df_train['Outcome']\n",
    "\n",
    "X_test = df_test.values\n",
    "y_test = pd.read_csv('data/diabetes_answers.csv')['Outcome']\n",
    "\n",
    "y_pred = classification(X_train, y_train, X_test)\n",
    "assert sklearn.metrics.accuracy_score(y_test, y_pred) > 0.74\n",
    "######################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Переобучение"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В [папке data](data) вы можете найти данные для бинарной классификации (файлы `overfit_trian.csv`, `overfit_test.csv`). Вам на вход подается тренировочная и тестовая выборки из файла. \n",
    "\n",
    "Верните такую обученную модель, которая на тренировочной выборке дает $accuracy > 0.97$, а на тестовом $accuracy < 0.7$.\n",
    "\n",
    "[$accuracy$](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) - доля правильных ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def overfitting(X_train: np.array, y_train: np.array, X_test: np.array, y_test: np.array):\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "df_train = pd.read_csv('data/overfit_train.csv')\n",
    "df_test = pd.read_csv('data/overfit_test.csv')\n",
    "\n",
    "X_train = df_train.drop(columns=['y']).values\n",
    "y_train = df_train['y']\n",
    "\n",
    "X_test = df_test.drop(columns=['y']).values\n",
    "y_test = df_test['y']\n",
    "\n",
    "model = overfitting(X_train, y_train, X_test, y_test)\n",
    "\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred =  model.predict(X_test)\n",
    "assert sklearn.metrics.accuracy_score(y_train, y_train_pred) > 0.97\n",
    "assert sklearn.metrics.accuracy_score(y_test, y_test_pred) < 0.7\n",
    "######################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Мой KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваша задача реализовать свой простой KNNClassifier для бинарных данных. Вам нужно реализовать 3 метода:\n",
    "\n",
    "* `init` - начальная инициализация\n",
    "* `fit` - обучение классификатора\n",
    "* `predict` - предсказание для новых объектов\n",
    "* `predict_proba` - предсказание вероятностей новых объектов\n",
    "\n",
    "У нашего классификатора будет лишь один гиперпараметр - количество соседей $k$. Во избежании тонкостей: $k$ - нечетное.\n",
    "\n",
    "На вход будет подаваться выборка объектов $X$, у которых ровно 2 числовых признака. $y$ - результат бинарной классификации $0$ или $1$.\n",
    "\n",
    "Метрика ближайших элементов - Эвклидова.\n",
    "\n",
    "Напоминание: $y$ - одномерный массив, $X$ - двумерный массив, по $0$-ой оси которой расположены объекты.\n",
    "\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "X_train = np.array([[1, 1], [1, -1], [-1,-1], [-1, 1]])\n",
    "y_train = np.array([1, 1, 0, 0])\n",
    "\n",
    "model = KNN(k=3).fit(X_train, y_train)\n",
    "y_pred = model.predict(np.array([[0.5, 0.5], [ -0.5,  -0.5]]))\n",
    "y_prob = model.predict_proba(np.array([[0.5, 0.5], [-0.5, -0.5]]))\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "y_pred = np.array([1., 0.])\n",
    "y_prob = np.array([[0.33, 0.667],\n",
    "                   [0.667, 0.33]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    def __init__(self, k=3):\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train: np.array, y_train:np.array): #обучаем классификатор\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_test: np.array): #предсказываем значения\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass\n",
    "    \n",
    "    def predict_proba(self, X_test: np.array): #предсказываем вероятности\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "######################################################\n",
    "X_clf = np.array([[1, 1], [1, -1], [-1,-1], [-1, 1]])\n",
    "y_clf = np.array([1, 1, 0, 0])\n",
    "\n",
    "model = KNN(k=3).fit(X_clf, y_clf)\n",
    "\n",
    "assert_equal(model.predict(np.array([[-0.5, -0.5]])), np.array([0.]))\n",
    "assert_equal(model.predict(np.array([[ 0.5,  0.5]])), np.array([1.]))\n",
    "assert_almost_equal(model.predict_proba(np.array([[0.5, 0.5], [-0.5, -0.5]])), \n",
    "                    np.array([[0.33, 0.667],\n",
    "                              [0.667, 0.33]]), \n",
    "                    decimal=2)\n",
    "######################################################\n",
    "np.random.seed(1337)\n",
    "n = 200\n",
    "a = np.random.normal(loc=0, scale=1, size=(n, 2)) # первый класс\n",
    "b = np.random.normal(loc=3, scale=2, size=(n, 2)) # второй класс\n",
    "X = np.vstack([a, b]) # двумерный количественный признак\n",
    "y = np.hstack([np.zeros(n), np.ones(n)]) # бинарный признак\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, random_state=1645)\n",
    "\n",
    "model = KNN(k=3).fit(X_train, y_train)\n",
    "model_real = KNeighborsClassifier(n_neighbors=3).fit(X_train, y_train)\n",
    "\n",
    "assert_array_almost_equal(model.predict(X_test), model_real.predict(X_test))\n",
    "assert_array_almost_equal(model.predict_proba(X_test), model_real.predict_proba(X_test))\n",
    "######################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Моя Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вам предстоит реализовать свою простейшую линейную регрессию по функционалу $MSE$.\n",
    "\n",
    "Линейная регрессия выглядит следующим образом:\n",
    "$$a(x) = w_1x + w_0$$\n",
    "\n",
    "Необходимо найти такие $w_0$ и $w_1$, при которых минимизируется значение\n",
    "\n",
    "$$MSE(X,Y) = \\frac{1}{n}\\sum_{i=1}^{n}(a(x_i) - y_i)^2$$\n",
    "\n",
    "Выведите формулы для $w_0$ и $w_1$ аналитически и реализуйте следующие методы класса \n",
    "\n",
    "* `init` - начальная инициализация\n",
    "* `fit` - обучение классификатора\n",
    "* `predict` - предсказание для новых объектов\n",
    "\n",
    "После обучения у модели должен присутствовать атрибут `model.coef_` из которого можно получить коэффициенты регрессии в порядке: $w_1$, $w_0$.\n",
    "\n",
    "Гиперпараметры отсутствуют.\n",
    "\n",
    "На вход будут подаваться два массива $X\\in \\mathbb{R}^{n}$ и $Y \\in \\mathbb{R}^{n}$.\n",
    "\n",
    "Метрика - Евклидова.\n",
    "\n",
    "### Sample 1\n",
    "#### Input:\n",
    "```python\n",
    "X_train = np.array([[1], [2]])\n",
    "y_train = np.array([1, 2])\n",
    "\n",
    "model = LinReg().fit(X_train, y_train)\n",
    "y_pred = model.predict(np.array([[3],[4]]))\n",
    "\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "y_pred = np.array([3, 4])\n",
    "model.coef_ = np.array([1., 0.])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg():\n",
    "    def __init__(self):\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass\n",
    "\n",
    "    def fit(self, X_train: np.array, y_train:np.array): #обучаем регрессию\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_test: np.array): #предсказываем значения\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "X_reg = np.array([[1], [2]])\n",
    "y_reg = np.array([1, 2])\n",
    "\n",
    "model = LinReg().fit(X_reg, y_reg)\n",
    "assert_array_almost_equal(model.predict(np.array([[3],[4]])), np.array([3, 4]), decimal=2)\n",
    "\n",
    "assert_array_almost_equal(model.predict(np.array([[0]])), np.array([0]), decimal=2)\n",
    "\n",
    "assert_array_almost_equal(model.coef_, np.array([1., 0.]), decimal=2)\n",
    "######################################################\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_reg, y_reg = make_regression(n_samples=200, n_features=1, n_targets=1)\n",
    "\n",
    "model = LinearRegression().fit(X_reg, y_reg)\n",
    "model2 = LinReg().fit(X_reg, y_reg)\n",
    "\n",
    "coef_real = np.array([model.coef_[0], model.predict(np.array([[0]]))[0]])\n",
    "coef_my = model2.coef_\n",
    "\n",
    "assert_array_almost_equal(coef_my, coef_real, decimal=3)\n",
    "######################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Наивный (зато свой) Байес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требуется написать свой классификатор, на основе наивного баеса. Необходимо реализовать аналог `MultinomialNB`. \n",
    "\n",
    "$$y_{test} = argmax_{label}\\ln{P(y=label)} + \\sum_{i=1}^{m}\\ln{(P(x_i=value|y = label) + \\alpha)}, ~~~ label\\in\\{0,1\\}$$\n",
    "\n",
    "На вход подаются численные категориальные признаки. Классы: $0$ и $1$. У классификатора будет единственный параметр - $alpha$.\n",
    "\n",
    "Вспомогательные поля для упращения решения задачи:\n",
    "Поле `apriori` - это словарь со значениями априорных вероятностей: $P(y = 0)$ и $P(y = 1)$.\n",
    "\n",
    "Поле `posterior` - это словарь со значениями условных (апостериорных) вероятностей: $posterior[(label, i, value)] = P(x_i=value|y = label)$.\n",
    "\n",
    "* `label` - значение y\n",
    "* `i` - номер фичи в том порядке как и во входном `X_clf`\n",
    "* `value` - значение фичи\n",
    "\n",
    "\n",
    "### Sample 1:\n",
    "#### Input:\n",
    "```python\n",
    "X_clf = np.array([[10, 20], [10, 30], [20,20], [20, 30], [20, 40], [20, 40]])\n",
    "y_clf = np.array([1, 1, 0, 0, 0, 0])\n",
    "\n",
    "model = MyNaiveBayes(alpha=0.01).fit(X_clf, y_clf)\n",
    "\n",
    "\n",
    "y_pred = model.predict(np.array([[10, 20], [20, 60]]))\n",
    "```\n",
    "#### Output:\n",
    "```python\n",
    "y_pred = [1, 0]\n",
    "\n",
    "model.apriori = {0: 0.666666, 1: 0.333333}\n",
    "\n",
    "model.posterior = {(1, 0, 10): 1.0, (1, 1, 20): 0.5,  (1, 1, 30): 0.5,\n",
    "                   (0, 0, 20): 1.0, (0, 1, 20): 0.25, (0, 1, 30): 0.25, (0, 1, 40): 0.5}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import log\n",
    "\n",
    "class MyNaiveBayes():\n",
    "    def __init__(self, alpha=0.01):\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        self.alpha = alpha\n",
    "        self.apriori = {0: 0, 1:0}\n",
    "        self.posterior = defaultdict(lambda: 0)\n",
    "        pass\n",
    "        \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        assert X.ndim == 2\n",
    "        assert y.ndim == 1\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        return self\n",
    "            \n",
    "    def predict(self, X: np.ndarray):\n",
    "        assert X.ndim == 2\n",
    "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "X_clf = np.array([[10, 20], [10, 30], [20,20], [20, 30], [20, 40], [20, 40]])\n",
    "y_clf = np.array([1, 1, 0, 0, 0, 0])\n",
    "\n",
    "model = MyNaiveBayes(alpha=0.01).fit(X_clf, y_clf)\n",
    "\n",
    "assert np.abs(model.apriori[0] - 0.666) < 0.01\n",
    "assert np.abs(model.apriori[1] - 0.333) < 0.01\n",
    "assert model.posterior[(1, 0, 10)] == 1.0\n",
    "assert model.posterior[(1, 1, 30)] == 0.5\n",
    "assert model.posterior[(0, 0, 20)] == 1.0\n",
    "assert model.posterior[(0, 1, 20)] == 0.25\n",
    "assert model.posterior[(0, 1, 40)] == 0.5\n",
    "\n",
    "assert_equal(model.predict(np.array([[10, 20], [20, 60]])), np.array([1, 0]))\n",
    "######################################################\n",
    "X_clf = np.array([[1, 1], [1, -1], [-1,-1], [-1, 1]])\n",
    "y_clf = np.array([1, 1, 0, 0])\n",
    "\n",
    "model = MyNaiveBayes(alpha=0.01).fit(X_clf, y_clf)\n",
    "\n",
    "assert np.abs(model.apriori[0] - 0.5) < 0.01\n",
    "assert np.abs(model.apriori[1] - 0.5) < 0.01\n",
    "assert model.posterior[(0,1,1)]== 0.5\n",
    "assert model.posterior[(1,0,1)]== 1.0\n",
    "\n",
    "\n",
    "assert_equal(model.predict(np.array([[1, 2], [-1, -2]])), np.array([1, 0]))\n",
    "\n",
    "######################################################\n",
    "X_clf = np.array([[2], [2], [4]])\n",
    "y_clf = np.array([0, 0, 1])\n",
    "\n",
    "model = MyNaiveBayes(alpha=0.01).fit(X_clf, y_clf)\n",
    "\n",
    "\n",
    "assert np.abs(model.apriori[0] - 0.666) < 0.01\n",
    "assert np.abs(model.apriori[1] - 0.333) < 0.01\n",
    "assert model.posterior[(0,0,2)] == 1.0\n",
    "assert model.posterior[(1,0,4)] == 1.0\n",
    "\n",
    "\n",
    "\n",
    "assert_equal(model.predict(np.array([[2], [4]])), np.array([0, 1]))\n",
    "######################################################\n",
    "X_clf = np.array([[4], [4], [4], [4], [2], [2], [2], [2], [2]])\n",
    "y_clf = np.array([0, 0, 0, 0, 0, 0, 0, 1, 1])\n",
    "\n",
    "model = MyNaiveBayes(alpha=0.01).fit(X_clf, y_clf)\n",
    "\n",
    "assert np.abs(model.apriori[0] - 0.777) < 0.01\n",
    "assert np.abs(model.apriori[1] - 0.222) < 0.01\n",
    "assert np.abs(model.posterior[(0,0,4)] - 0.5714) < 0.01\n",
    "assert np.abs(model.posterior[(0,0,2)] - 0.4285) < 0.01\n",
    "assert model.posterior[(1,0,2)] == 1.0\n",
    "\n",
    "assert_equal(model.predict(np.array([[2], [4]])), np.array([0, 0]))\n",
    "######################################################\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "random_state = 1448\n",
    "X, y = make_classification(n_samples=500, n_features=4, n_informative=2,\n",
    "                           scale=5, random_state=random_state)\n",
    "\n",
    "X = X.astype(np.int) \n",
    "X += np.abs(np.min(X))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                    random_state=random_state,\n",
    "                                                    stratify=y)\n",
    "\n",
    "clf = MyNaiveBayes(alpha=0.01).fit(X_train, y_train)\n",
    "assert accuracy_score(y_test, clf.predict(X_test)) > 0.9\n",
    "######################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Злобные твиты"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наивный Байес очень хорошо подходит для Анализа тональности текста. То есть определить несет текст позитивный или негативный вайб :) \n",
    "\n",
    "В данной задаче вам даны [твиты про разные авиакомпании](data) (файлы `tweets_train.csv`, `tweets_test.csv`). Требуется построить классификатор, который бы определял имеет ли твит положительную или негативную окраску. Напишите функцию `predict`, который возвращает массив, где 1 - это позитивный, 0 - негативный. \n",
    "\n",
    "В данной задаче вам понадобятся `TweetTokenizer` и `CountVectorizer`. \n",
    "\n",
    "* `TweetTokenizer` и любой tokenizer самостоятельно разбивает строку на слова как-то их модифицировав.\n",
    "* `CountVectorizer` превращает предложение в вектор чисел основываясь на их частоте, используя токенайзер.\n",
    "\n",
    "Задача делится на 2 пункта: \n",
    "\n",
    "* Preprocessing: переведите все слова в нижний регистр, токенизируйте слова с помощью `TweetTokenizer`, а дальше опять соберите в предложение. Проделайте это и в $X_{train}$ и $X_{test}$\n",
    "* Predict: переведите предложения в вектора количеств с помощь `CountVectorizer`. Обучите модель на данных и предскажите ответ.\n",
    "\n",
    "Чтобы получить баллы надо побить accuracy = 0.88\n",
    "\n",
    "\n",
    "P.S Можете посмотреть топ слов, которые с наибольшей вероятностью относятся к позитивным и негативным классам. \n",
    "\n",
    "P.P.S. Если ничего не понятно: можете изучить различные kernel на [kaggle](https://www.kaggle.com/crowdflower/twitter-airline-sentiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer, TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def predict(df_train: pd.DataFrame, df_test: pd.DataFrame):\n",
    "    \n",
    "    # preprocess data here\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    model = MultinomialNB ...\n",
    "        \n",
    "    # fit model\n",
    "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
    "    return model.predict(...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_train = pd.read_csv('data/tweets_train.csv')\n",
    "df_test = pd.read_csv('data/tweets_test.csv')\n",
    "\n",
    "y_test = ((df_test['airline_sentiment'] == 'positive').astype(np.int))\n",
    "X_test = df_test.drop(columns='airline_sentiment')\n",
    "\n",
    "assert accuracy_score(y_test, predict(df_train, df_test)) > 0.88\n",
    "######################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
